breaks <- h$breaks; nB <- length(breaks)
y <- h$counts; y <- y/max(y)
rect(breaks[-nB], 0, breaks[-1], y, col = "cyan", ...)
}
datos_cualit = datos[c(3,4,5,6,7,8,12,13,14,15,16,22,21)]
datos_cualit = datos[c(3,4,5,6,7,8,12)]
pairs(datos_cualit,cex = 1.2, pch = 16,
diag.panel = panel.hist,
cex.labels = 2, font.labels = 2)
1+1
hist(datos$price)
1+1
hist(datos$price)
hist(datos$log_price)
datos$log_sqft_living = log(datos$sqft_living)
hist(datos$log_sqft_living)
datos_cualit = datos[c(3,4,5,6,7,8,12,13,14,15,16,22,21)]
1+1
pairs(datos_cualit,cex = 1.2, pch = 16,
diag.panel = panel.hist,
cex.labels = 2, font.labels = 2)
1+1
hist(datos_cualit[3])
hist(datos[5])
hist(datos)
datos[1]
datos[1,1]
datos[1,1:20]
datos[,1]
hist(datos[,1])
View(datos)
for (i in 1:23) {
hist(datos[,i])
}
for (i in c(1,3:23) {
for (i in c(3:23) {
for (i in 3:23) {
hist(datos[,i])
}
for (i in 3:23) {
hist(datos[,i])
}
for (i in 3:23) {
hist(log(datos[,i]))
}
for (i in 3:23) {
hist(log(datos[,i]),labels = "i")
}
hist(log(datos[,i]),labels = i)
for (i in 3:23) {
hist(log(datos[,i]),labels = i)
}
hist((datos[,i]),labels = i)
for (i in 3:23) {
hist((datos[,i]),labels = i)
}
hist(datos$)
hist(datos$price)
hist(datos$price)
hist(datos$bedrooms)
hist(datos$bathrooms)
hist(datos$sqft_living)
hist(log(datos$sqft_living))
hist(datos$sqft_lot)
hist(log(datos$sqft_lot))
hist(datos$floors)
hist(datos$sqft_above)
hist(log(datos$sqft_above))
hist(datos$sqft_above)
hist(datos$sqft_basement)
hist(datos$sqft_basement)
hist(log(datos$sqft_above))
hist(datos$sqft_basement)
hist(log(datos$sqft_basement))
hist(datos$yr_built)
hist(datos$yr_renovated)
hist(datos$sqft_living15)
hist(log(datos$sqft_living15))
hist(datos$sqft_living15)
hist(datos$sqft_lot15)
hist(log(datos$sqft_lot15))
hist(datos$condition)
hist(datos$grade)
hist(log(datos$grade))
hist(datos$price)
hist(datos$bedrooms)
hist(datos$bathrooms)
hist(datos$sqft_living)
hist(datos$sqft_lot)
hist(datos$floors)
hist(datos$sqft_above)
hist(datos$sqft_basement)
hist(datos$yr_built)
hist(datos$yr_renovated)
hist(datos$sqft_living15)
hist(datos$sqft_lot15)
hist(datos$condition)
hist(datos$grade)
hist(log(datos$price))
hist(log(datos$sqft_living))
hist(log(datos$sqft_lot))
hist(log(datos$sqft_above))
hist(log(datos$sqft_basement))
hist(log(datos$sqft_living15))
hist(log(datos$sqft_lot15))
hist(log(datos$grade))
datos2 <- read.table('kc_house_data.csv', header = TRUE, sep =',')
library(rpart)
library(rpart.plot)
#Buscamos los datos atípicos a mano
hist(datos2$sqft_living)
aux = datos2$sqft_living>10000
datos = datos2[!aux,] #negación lógica
hist(datos$price)
hist(datos$bedrooms)
hist(datos$bathrooms)
hist(datos$sqft_living)
hist(datos$sqft_lot)
hist(datos$floors)
hist(datos$sqft_above)
hist(datos$sqft_basement)
hist(datos$yr_built)
hist(datos$yr_renovated)
hist(datos$sqft_living15)
hist(datos$sqft_lot15)
hist(datos$condition)
hist(datos$grade)
hist(log(datos$price))
hist(log(datos$sqft_living))
hist(log(datos$sqft_lot))
hist(log(datos$sqft_above))
hist(log(datos$sqft_basement))
hist(log(datos$sqft_living15))
hist(log(datos$sqft_lot15))
hist(log(datos$grade))
#Buscamos los datos atípicos a mano
hist(datos2$sqft_living)
aux = datos2$sqft_living>10000
datos = datos2[!aux,] #negación lógica
#Le quito la variable 1 y 3:
datos2 = datos[-c(1:3)]
datos2
#Buscamos los datos atípicos (influencia) (regresión normal, no vale rpart)
datos_regl = lm(log_price ~., data = datos2)
potencial <- hatvalues(datos_regl)
#Buscamos los datos atípicos (influencia) (regresión normal, no vale rpart)
datos_regl = lm(log_price ~., data = datos2)
#Hacemos el log de la variable respuesta para arreglar la asimetría
datos$log_price = log(datos$price)
datos$log_sqft_living = log(datos$sqft_living)
#Buscamos los datos atípicos (influencia) (regresión normal, no vale rpart)
datos_regl = lm(log_price ~., data = datos2)
datos <- read.table('kc_house_data.csv', header = TRUE, sep =',')
library(rpart)
library(rpart.plot)
#Hacemos el log de la variable respuesta para arreglar la asimetría
datos$log_price = log(datos$price)
datos$log_sqft_living = log(datos$sqft_living)
hist(datos$price)
hist(datos$bedrooms)
hist(datos$bathrooms)
hist(datos$sqft_living)
hist(datos$sqft_lot)
hist(datos$floors)
hist(datos$sqft_above)
hist(datos$sqft_basement)
hist(datos$yr_built)
hist(datos$yr_renovated)
hist(datos$sqft_living15)
hist(datos$sqft_lot15)
hist(datos$condition)
hist(datos$grade)
hist(log(datos$price))
hist(log(datos$sqft_living))
hist(log(datos$sqft_lot))
hist(log(datos$sqft_above))
hist(log(datos$sqft_basement))
hist(log(datos$sqft_living15))
hist(log(datos$sqft_lot15))
hist(log(datos$grade))
#Buscamos los datos atípicos a mano
hist(datos$sqft_living)
aux = datos$sqft_living>10000
datos = datos[!aux,] #negación lógica
#Le quito la variable 1 y 3:
datos2 = datos[-c(1:3)]
datos2
#Buscamos los datos atípicos (influencia) (regresión normal, no vale rpart)
datos_regl = lm(log_price ~., data = datos2)
potencial <- hatvalues(datos_regl)
cook <- cooks.distance(datos_regl)
barplot(potencial, col="blue", xlab="Potencial")
barplot(cook, col="blue", xlab="Distancia de Cook")
sum(potencial<0.9)
summary(datos_regl)
#Regresión en los datos
datos_reg <- rpart(log_price ~ ., data=datos2, cp = 0.000005)
datos_reg
cp_t = printcp(datos_reg)
cp_t
summary(datos_reg)
rsq.rpart(datos_reg)
plotcp(datos_reg)
rpart.plot(datos_reg)
#rpart.plot(datos_reg)
which.min(cp_t[,4])
#Regresión en los datos
datos_reg <- rpart(log_price ~ ., data=datos2, cp = 0.000005)
datos_reg
cp_t = printcp(datos_reg)
cp_t
summary(datos_reg)
rsq.rpart(datos_reg)
plotcp(datos_reg)
#rpart.plot(datos_reg)
which.min(cp_t[,4])
#Regresión en los datos
datos_reg <- rpart(log_price ~ ., data=datos2, cp = 0.000005)
datos_reg
cp_t = printcp(datos_reg)
cp_t
summary(datos_reg)
rsq.rpart(datos_reg)
plotcp(datos_reg)
#rpart.plot(datos_reg)
which.min(cp_t[,4])
#Regresión en los datos
datos_reg <- rpart(log_price ~ ., data=datos2, cp = 0.000005)
cp_t = printcp(datos_reg)
#summary(datos_reg)
#rsq.rpart(datos_reg)
#plotcp(datos_reg)
#rpart.plot(datos_reg)
which.min(cp_t[,4])
#Residuos del modelo
plot(predict(datos_reg), jitter(resid(datos_reg)))
#Regresión en los datos
datos_reg <- rpart(log_price ~ ., data=datos2, cp = 0.000005)
cp_t = printcp(datos_reg)
#summary(datos_reg)
#rsq.rpart(datos_reg)
#plotcp(datos_reg)
#rpart.plot(datos_reg)
which.min(cp_t[,4])
#Regresión en los datos
datos_reg <- rpart(log_price ~ ., data=datos2, cp = 0.000005)
cp_t = printcp(datos_reg)
#summary(datos_reg)
#rsq.rpart(datos_reg)
#plotcp(datos_reg)
#rpart.plot(datos_reg)
which.min(cp_t[,4])
cp_t
#summary(datos_reg)
#rsq.rpart(datos_reg)
#plotcp(datos_reg)
#rpart.plot(datos_reg)
one_se = p_t[which.min(cp_t[,4]),4] + cp_t[which.min(cp_t[,4]),5]
#summary(datos_reg)
#rsq.rpart(datos_reg)
#plotcp(datos_reg)
#rpart.plot(datos_reg)
one_se = cp_t[which.min(cp_t[,4]),4] + cp_t[which.min(cp_t[,4]),5]
one_se
#Regresión en los datos
datos_reg <- rpart(log_price ~ ., data=datos2, cp = 0.000005)
cp_t = printcp(datos_reg)
#summary(datos_reg)
#rsq.rpart(datos_reg)
#plotcp(datos_reg)
#rpart.plot(datos_reg)
one_se = cp_t[which.min(cp_t[,4]),4] + cp_t[which.min(cp_t[,4]),5]
one_se
for (i in 1:30) {
datos_reg <- rpart(log_price ~ ., data=datos2, cp = 0.000005)
cp_t = printcp(datos_reg)
one_se = cp_t[which.min(cp_t[,4]),4] + cp_t[which.min(cp_t[,4]),5]
one_se
}
#Regresión en los datos
datos_reg <- rpart(log_price ~ ., data=datos2, cp = 0.000005)
cp_t = printcp(datos_reg)
cp_t = cptable(datos_reg)
for (i in 1:30) {
datos_reg <- rpart(log_price ~ ., data=datos2, cp = 0.000005)
one_se = datos_reg$cptable[which.min(cp_t[,4]),4] + datos_reg$cptable[which.min(cp_t[,4]),5]
one_se
}
for (i in 1:30) {
datos_reg <- rpart(log_price ~ ., data=datos2, cp = 0.000005)
one_se = datos_reg$cptable[which.min(cp_t[,4]),4] + datos_reg$cptable[which.min(cp_t[,4]),5]
print(one_se)
}
## Primero elegimos el número de capas de cross-validation
fold = 10
## Observaciones
n = 21610
## Tamaño de la muestra test
n_test = n/fold
## Tamaño de la muestra trainning
n_tr = n - n_test
vn = 1:n
## Hacemos una tabla para almacenar los datos
v_tabla_optimo = matrix(rep(NA,fold*4), nrow = fold)
#cp óptimo
cp_optimo = sqrt(datos_reg$cptable[cp_optimo_pos,"CP"]*datos_reg$cptable[cp_optimo_pos-1,"CP"])
for (i in 1:fold ) {
i_test = 1:n_test + (i - 1)*n_test
i_tr = vn[-i_test]
datos_tr = datos[i_tr,]
datos_test = datos[i_test,]
tcar_eficacia <- rpart(log_price ~ ., data=datos ,control = rpart.control(xval = 10, minbucket = 1, cp = 0.000000005 ))
tcar_pruned_eficacia = prune(tcar_eficacia, cp_optimo)
tcar_pruned_table = table(predict(tcar_pruned_eficacia, datos_test, type = "vector"), datos_test$log_price)
v_tabla_optimo[i,] = matrix(tcar_pruned_table, nrow = 1)
}
datos <- read.table('kc_house_data.csv', header = TRUE, sep =',')
library(rpart)
library(rpart.plot)
library(ranger)
set.seed(1999)
#Buscamos los datos atípicos a mano
hist(datos$sqft_living)
aux = datos$sqft_living>10000
datos = datos[!aux,] #negación lógica
#Le quito la variable 1 y 3:
datos2 = datos[-c(1:3)]
datos2
#Buscamos los datos atípicos (influencia) (regresión normal, no vale rpart)
datos_regl = lm(log_price ~., data = datos2)
potencial <- hatvalues(datos_regl)
cook <- cooks.distance(datos_regl)
barplot(potencial, col="blue", xlab="Potencial")
barplot(cook, col="blue", xlab="Distancia de Cook")
summary(datos_regl)
#Regresión en los datos
set.seed(1999)
datos_reg <- rpart(log_price ~ ., data=datos, cp = 0.0000000005)
datos_reg$cptable
#summary(datos_reg)
#rsq.rpart(datos_reg)
#plotcp(datos_reg)
#rpart.plot(datos_reg)
one_se = datos_reg$cptable[which.min(cp_t[,4]),4] + datos_reg$cptable[which.min(cp_t[,4]),5]
one_se
#Todo va bien
for (i in 1:30) {
set.seed((1999))
datos_reg <- rpart(log_price ~ ., data=datos2, cp = 0.000005)
one_se = datos_reg$cptable[which.min(cp_t[,4]),4] + datos_reg$cptable[which.min(cp_t[,4]),5]
print(one_se)
}
a = datos_reg$cptable[,4] > one_se
cp_optimo_pos = min(which(a == FALSE))
cp_optimo_pos
cp_optimo_error = sqrt(datos_reg$cptable[which.min(datos_reg$cptable[,"xerror"]),"CP"]*datos_reg$cptable[which.min(datos_reg$cptable[,"xerror"])-1,"CP"])
cp_optimo = sqrt(datos_reg$cptable[cp_optimo_pos,"CP"]*datos_reg$cptable[cp_optimo_pos-1,"CP"])
cp_optimo
datos_reg$cptable[cp_optimo_pos,"CP"]
datos_cualit = datos[c(3,4,5,6,7,8,12,13,14,15,16,22,21)]
cp_optimo_error = sqrt(datos_reg$cptable[which.min(datos_reg$cptable[,"xerror"]),"CP"]*datos_reg$cptable[which.min(datos_reg$cptable[,"xerror"])-1,"CP"])
cp_optimo = sqrt(datos_reg$cptable[cp_optimo_pos,"CP"]*datos_reg$cptable[cp_optimo_pos-1,"CP"])
cp_optimo
datos_reg$cptable[cp_optimo_pos,"CP"]
## Primero elegimos el número de capas de cross-validation
fold = 10
## Observaciones
n = 21610
## Tamaño de la muestra test
n_test = n/fold
## Tamaño de la muestra trainning
n_tr = n - n_test
vn = 1:n
## Hacemos una tabla para almacenar los datos
v_tabla_optimo = matrix(rep(NA,fold*4), nrow = fold)
#cp óptimo
cp_optimo = sqrt(datos_reg$cptable[cp_optimo_pos,"CP"]*datos_reg$cptable[cp_optimo_pos-1,"CP"])
for (i in 1:fold ) {
i_test = 1:n_test + (i - 1)*n_test
i_tr = vn[-i_test]
datos_tr = datos[i_tr,]
datos_test = datos[i_test,]
tcar_eficacia <- rpart(log_price ~ ., data=datos ,control = rpart.control(xval = 10, minbucket = 1, cp = 0.000000005 ))
tcar_pruned_eficacia = prune(tcar_eficacia, cp_optimo)
tcar_pruned_table = table(predict(tcar_pruned_eficacia, datos_test, type = "vector"), datos_test$log_price)
v_tabla_optimo[i,] = matrix(tcar_pruned_table, nrow = 1)
}
#Hacemos el log de la variable respuesta para arreglar la asimetría
datos$log_price = log(datos$price)
datos$log_sqft_living = log(datos$sqft_living)
for (i in 1:fold ) {
i_test = 1:n_test + (i - 1)*n_test
i_tr = vn[-i_test]
datos_tr = datos[i_tr,]
datos_test = datos[i_test,]
tcar_eficacia <- rpart(log_price ~ ., data=datos ,control = rpart.control(xval = 10, minbucket = 1, cp = 0.000000005 ))
tcar_pruned_eficacia = prune(tcar_eficacia, cp_optimo)
tcar_pruned_table = table(predict(tcar_pruned_eficacia, datos_test, type = "vector"), datos_test$log_price)
v_tabla_optimo[i,] = matrix(tcar_pruned_table, nrow = 1)
}
datos_reg <- rpart(log_price ~ ., data=datos, cp = 0.0000000005)
summary(datos_reg)
hist(datos$price)
hist(datos$bedrooms)
hist(datos$bathrooms)
hist(datos$sqft_living)
hist(datos$sqft_lot)
hist(datos$floors)
hist(datos$sqft_above)
hist(datos$sqft_basement)
hist(datos$yr_built)
hist(datos$yr_renovated)
hist(datos$sqft_living15)
hist(datos$sqft_lot15)
hist(datos$condition)
hist(datos$grade)
hist(log(datos$price))
hist(log(datos$sqft_living))
summary(datos_reg)
source("~/.active-rstudio-document")
n <- 100
beta0 <- 0
beta1 <- 3
x <- rnorm(n) # el modelo no asume normalidad de x
p = 1/(1+exp(-beta0-beta1*x))
y = rbinom(n, 1, p)
# Ajusta el modelo
reg = glm(y~x, family=binomial)
summary(reg)
datos <- data.frame(x = seq(-4, 4, 0.1))
datos
probabilidades <- predict(reg, datos, type = "response")
probabilidades
# por defecto calcula log p_i/(1-p_i), para calcular p_i usamos el argumento type
plot(x, y, pch = 21)
lines(datos$x, probabilidades, col = "blue", lwd = 2)
x <- rnorm(n) # el modelo no asume normalidad de x
x
p = 1/(1+exp(-beta0-beta1*x))
y
knitr::opts_chunk$set(echo = TRUE)
datos <- read.table('kc_house_data.csv', header = TRUE, sep =',')
library(rpart)
library(rpart.plot)
library(ranger)
library(ggplot2)
set.seed(732)
datos <- read.table('kc_house_data.csv', header = TRUE, sep =',')
library(rpart)
library(rpart.plot)
library(ranger)
set.seed(1999)
#Preparamos los datos para hacer la regresión, aplicamos el logaritmo para eliminar la asimetría y obtener una variable próxima a la normal
#Extraer fecha si me veo con fuerza
datos$log_price = log(datos$price)
#Hacemos el log de la variable respuesta para arreglar la asimetría
datos_sel = datos[c(3,4,5,6,7,8,9,10,11,12,13,14,15,17,20,21)]
datos_sel$log_price = log(datos$price) #Hacer el estudio de las dos
datos_sel$waterfront = factor(datos_sel$waterfront)
datos_sel$condition = factor(datos_sel$condition)
datos_sel$view = factor(datos_sel$view)
datos_sel$grade = factor(datos_sel$grade)
datos_sel$zipcode = factor(datos_sel$zipcode)
hist(datos$price)
#Buscamos los datos atípicos a mano
aux = datos$sqft_living>10000
datos = datos[!aux,] #negación lógica
datos_reg <- rpart(log_price ~ id + date + price + bathrooms + sqft_living + sqft_lot + floors +
waterfront + view + condition + grade + sqft_above + sqft_basement +
yr_built + zipcode +  sqft_living15 + sqft_lot15, data=datos_sel, cp = 0.0000000005)
datos_reg <- rpart(log_price ~ bathrooms + sqft_living + sqft_lot + floors +
waterfront + view + condition + grade + sqft_above + sqft_basement +
yr_built + zipcode +  sqft_living15 + sqft_lot15, data=datos_sel, cp = 0.0000000005)
datos_reg <- rpart(log_price ~ bathrooms + sqft_living + sqft_lot + floors +
waterfront + view + condition + grade + sqft_above + sqft_basement +
yr_built + zipcode +  sqft_living15 + sqft_lot15, data=datos_sel, cp = 0.000000000005)
datos_reg$cptable
datos_reg$cptable[which.min(cp_t[,4]),4]
datos_reg$cptable[which.min(datos_reg$cptable[,4]),4]
datos_reg$cptable[which.min(datos_reg$cptable[,4]),]
datos_reg <- rpart(log_price ~ bathrooms + sqft_living + sqft_lot + floors +
waterfront + view + condition + grade + sqft_above + sqft_basement +
yr_built + zipcode +  sqft_living15 + sqft_lot15, data=datos_sel, cp = 0)
datos_reg$cptable[which.min(datos_reg$cptable[,4]),]
set.seed(1999)
datos_reg <- rpart(log_price ~ bathrooms + sqft_living + sqft_lot + floors +
waterfront + view + condition + grade + sqft_above + sqft_basement +
yr_built + zipcode +  sqft_living15 + sqft_lot15, data=datos_sel, cp = 0)
datos_reg$cptable[which.min(datos_reg$cptable[,4]),]
datos_reg <- rpart(log_price ~ bathrooms + sqft_living + sqft_lot + floors +
waterfront + view + condition + grade + sqft_above + sqft_basement +
yr_built + zipcode +  sqft_living15 + sqft_lot15, data=datos_sel, cp = 0.000000000000000005)
set.seed(1999)
datos_reg <- rpart(log_price ~ bathrooms + sqft_living + sqft_lot + floors +
waterfront + view + condition + grade + sqft_above + sqft_basement +
yr_built + zipcode +  sqft_living15 + sqft_lot15, data=datos_sel, cp = 0.000000000000000005)
datos_reg$cptable[which.min(datos_reg$cptable[,4]),]
set.seed(732)
datos_reg <- rpart(log_price ~ bathrooms + sqft_living + sqft_lot + floors +
waterfront + view + condition + grade + sqft_above + sqft_basement +
yr_built + zipcode +  sqft_living15 + sqft_lot15, data=datos_sel, cp = 0.000000000000000005)
datos_reg$cptable[which.min(datos_reg$cptable[,4]),]
Aquí tenemos toda la información, pero lo que a nosotros nos interesa es elegir el mejor parámetro de complejidad (*cp*) para realizar la poda a nuestro árbol. Vamos a ver cuales son los optimos mostrándolos en una tabla. La tabla es demasiado extensa, por lo que vamos a omitir su presentación, pero la usaremos para extraer los valores.
one_se = datos_reg$cptable[which.min(datos_reg$cptable [,4]),4] + datos_reg$cptable[which.min(datos_reg$cptable [,4]),5]
a = datos_reg$cptable[,4] > one_se
cp_optimo_pos = min(which(a == FALSE))
cp_se = sqrt(datos_reg$cptable[cp_optimo_pos,"CP"]*datos_reg$cptable[cp_optimo_pos-1,"CP"])
one_se
cp_se
cp_se = sqrt(datos_reg$cptable[cp_optimo_pos,"CP"]*datos_reg$cptable[cp_optimo_pos-1,"CP"])
datos_reg$cptable[which.min(datos_reg$cptable[,4]),]
datos_reg$cptable[which.min(datos_reg$cptable[,4]),1]
